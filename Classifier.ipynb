{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "data = pd.read_csv('poems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poem</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Humanity i love you because you would rather b...</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Whose woods these are I think I know. His hous...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Adam lay ibounden,Bounden in a bond; Four thou...</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Listen, children: Your father is dead. From hi...</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>You are a nobodyuntil another man leavesa note...</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Poem   Genre\n",
       "679  Humanity i love you because you would rather b...   Death\n",
       "467  Whose woods these are I think I know. His hous...  Nature\n",
       "244  Adam lay ibounden,Bounden in a bond; Four thou...   Death\n",
       "104  Listen, children: Your father is dead. From hi...   Death\n",
       "805  You are a nobodyuntil another man leavesa note...    Love"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio     254\n",
       "Nature    253\n",
       "Death     250\n",
       "Love      242\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poem</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>humanity love would rather black boots success...</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>whose woods i think i know  his house village ...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>adam lay ibounden bounden bond  four thousand ...</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>listen  children  your father dead  from old c...</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>you nobodyuntil another man leavesa note wiper...</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Poem   Genre\n",
       "679  humanity love would rather black boots success...   Death\n",
       "467  whose woods i think i know  his house village ...  Nature\n",
       "244  adam lay ibounden bounden bond  four thousand ...   Death\n",
       "104  listen  children  your father dead  from old c...   Death\n",
       "805  you nobodyuntil another man leavesa note wiper...    Love"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Removing stop words from poems\n",
    "data['Poem'] = data['Poem'].str.split(' ').apply(lambda x: ' '.join(k for k in x if k not in stop))\n",
    "\n",
    "# Converting poems to lowercase\n",
    "data['Poem'] = data['Poem'].apply(lambda x: x.lower())\n",
    "\n",
    "# Removing punctuations and all digits from poems\n",
    "filterString = string.punctuation + '“”|”' + string.digits\n",
    "data['Poem'] = data['Poem'].apply(lambda x: x.translate(str.maketrans(filterString,' '*len(filterString),'')))\n",
    "\n",
    "# data['Poem'] = data['Poem'].apply(lambda x: x.translate(str.maketrans('','',string.punctuation + '“”|”' + string.digits)))\n",
    "# Removing all digits from poems\n",
    "# data['Poem'] = data['Poem'].apply(lambda x: x.translate(str.maketrans('','',string.digits)))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e5b1a9a9a34306a5c82b34dfce878d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='genre', options=('Death', 'Audio', 'Nature', 'Love'), value='Death…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "from ipywidgets import interact\n",
    "\n",
    "genre_list = ['Death', 'Audio', 'Nature', 'Love']\n",
    "\n",
    "@interact\n",
    "def plot_word_cloud(genre=genre_list):\n",
    "    \n",
    "    sample_data = data[data['Genre'] == genre]\n",
    "    text = ' '.join(sample_data['Poem'].tolist())\n",
    "    wordcloud = WordCloud(max_font_size=60, stopwords=stop).generate(text)\n",
    "        \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('WordCloud for {}'.format(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = data['Poem']\n",
    "\n",
    "# test = test.str.replace('[^A-z ]','').str.replace(' +',' ').str.strip()\n",
    "\n",
    "# splitwords = [ nltk.word_tokenize( str(a) ) for a in test ]\n",
    "\n",
    "# document = list()\n",
    "\n",
    "# print(splitwords)\n",
    "# print(type(splitwords))\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# doc = [tuple(r) for r in data.values]\n",
    "# # print(test)\n",
    "\n",
    "# document = list()\n",
    "# for k in doc:\n",
    "# #     print(word_tokenize(k[0]))\n",
    "#     document.append([word_tokenize(k[0]),k[1]])\n",
    "    \n",
    "# print(document[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop_words=set(stopwords.words(\"english\"))\n",
    "# # print(stop_words)\n",
    "\n",
    "# filtered_sent=[]\n",
    "# for w in document:\n",
    "#     for j in w[0]:\n",
    "#          if j not in stop_words:\n",
    "#             filtered_sent.append(j)\n",
    "# print(\"Tokenized Sentence:\",document[0])\n",
    "# print(\"Filterd Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "# from sklearn.pipeline import make_pipeline, Pipeline\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data['Poem'] #Column for Feature\n",
    "# y = data['Genre'] #Column for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stop_words in [None, \"english\"]:\n",
    "\n",
    "#     vect = CountVectorizer(ngram_range=(1,1), stop_words=stop_words)\n",
    "#     data_dtm = vect.fit_transform(X)\n",
    "#     print('The shape of our dtm with stop_words={} is: {}'.format(stop_words, data_dtm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect = CountVectorizer(ngram_range=(1,2), stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "# X_train_dtm = vect.fit_transform(X_train)\n",
    "# X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# clf = MultinomialNB()\n",
    "\n",
    "# clf.fit(X_train_dtm, y_train)\n",
    "# y_pred = clf.predict(X_test_dtm)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.lancaster import LancasterStemmer\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# lancast_stemmer = LancasterStemmer()\n",
    "# porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Lyrics_Lancast_Stem'] = data['Poem'].apply(lambda x: ' '.join([lancast_stemmer.stem(y) if y not in ENGLISH_STOP_WORDS \n",
    "#                                                                      else y for y in x.split()]))\n",
    "# data['Lyrics_Porter_Stem'] = data['Poem'].apply(lambda x: ' '.join([porter_stemmer.stem(y) if y not in ENGLISH_STOP_WORDS \n",
    "#                                                                     else y for y in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Lancaster Stemming: {}\\nPorter Stemming: {}'.format(data.loc[1, 'Lyrics_Lancast_Stem'], data.loc[1, 'Lyrics_Porter_Stem']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lancast_vect = CountVectorizer(ngram_range=(1,1), stop_words=ENGLISH_STOP_WORDS)\n",
    "# porter_vect = CountVectorizer(ngram_range=(1,1), stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "# data_dtm_lancast = lancast_vect.fit_transform(data['Lyrics_Lancast_Stem'])\n",
    "# data_dtm_porter = porter_vect.fit_transform(data['Lyrics_Porter_Stem'])\n",
    "\n",
    "# print('The shape of our dtm after lancaster stemming is: {}'.format(data_dtm_lancast.shape))\n",
    "# print('The shape of our dtm after porter stemming is: {}'.format(data_dtm_porter.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X = data['Lyrics_Lancast_Stem']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=1)\n",
    "\n",
    "# pipe = make_pipeline(CountVectorizer(stop_words=ENGLISH_STOP_WORDS), MultinomialNB())\n",
    "\n",
    "# params = {\n",
    "#     'countvectorizer__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "#     'countvectorizer__min_df':[0, 2, 3, 4, 5, 6, 7, 8]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(pipe, params, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "# print(\"Best CV Score: {:.2f}\".format(grid.best_score_))\n",
    "# print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "# print(\"Score for test sample held out: {}\".format(accuracy_score(y_test, grid.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data['Lyrics_Porter_Stem']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=1)\n",
    "\n",
    "# pipe = make_pipeline(CountVectorizer(stop_words=ENGLISH_STOP_WORDS), MultinomialNB())\n",
    "\n",
    "# params = {\n",
    "#     'countvectorizer__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "#     'countvectorizer__min_df':[0, 2, 3, 4, 5, 6, 7, 8]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(pipe, params, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "# print(\"Best CV Score: {:.2f}\".format(grid.best_score_))\n",
    "# print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "# print(\"Score for test sample held out: {}\".format(accuracy_score(y_test, grid.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
